{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "先下載 MNIST 資料\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "from urllib.request import urlretrieve\n",
    "dataset = 'mnist.pkl.gz'\n",
    "def reporthook(a,b,c):\n",
    "    print(\"\\rdownloading: %5.1f%%\"%(a*b*100.0/c), end=\"\")\n",
    "    \n",
    "if not os.path.isfile(dataset):\n",
    "        origin = \"https://github.com/mnielsen/neural-networks-and-deep-learning/raw/master/data/mnist.pkl.gz\"\n",
    "        print('Downloading data from %s' % origin)\n",
    "        urlretrieve(origin, dataset, reporthook=reporthook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "with gzip.open(dataset, 'rb') as f:\n",
    "    train_set, validation_set, test_set = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 設定好訓練及測試資料\n",
    "train_X, train_y = train_set\n",
    "test_X, test_y = test_set\n",
    "# 設定成我們的格式\n",
    "train_X = train_X[..., None]\n",
    "test_X = test_X[..., None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 有 10 種類別，輸入的是 784 維\n",
    "print(train_X.shape)\n",
    "np.unique(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "def showX(X):\n",
    "    int_X = (X*255).clip(0,255).astype('uint8')\n",
    "    # N*784 -> N*28*28 -> 28*N*28 -> 28 * 28N\n",
    "    int_X_reshape = int_X.reshape(-1,28,28).swapaxes(0,1).reshape(28,-1)\n",
    "    display(Image.fromarray(int_X_reshape))\n",
    "# 訓練資料， X 的前 20 筆\n",
    "print(train_y[:20])\n",
    "showX(train_X[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 參考範例 softmax regression\n",
    "W = np.random.normal(size=(10, 784))\n",
    "b = np.random.normal(size=(10, 1))\n",
    "n_data = train_X.shape[0]\n",
    "# 紀錄 loss\n",
    "loss_history = []\n",
    "accuracy_history = []\n",
    "for epoch in range(5000):    \n",
    "    idx = np.random.choice(n_data, 300, replace=False)\n",
    "    X = train_X[idx]\n",
    "    y = train_y[idx]\n",
    "    one_y = np.eye(10)[y][..., None]\n",
    "    d = np.exp(W @ X + b)\n",
    "    q = d/d.sum(axis=(1,2), keepdims=True)\n",
    "    loss = -np.log(q[range(len(y)), y]).mean()\n",
    "    loss_history.append(loss)\n",
    "    accuracy = (q.argmax(axis=1).ravel() == y).mean()\n",
    "    accuracy_history.append(accuracy)\n",
    "    if epoch%100 == 0:\n",
    "        print(epoch, accuracy, loss)\n",
    "    grad_b_all = q - one_y\n",
    "    grad_b = grad_b_all.mean(axis=0)\n",
    "    grad_W_all = grad_b_all @ X.swapaxes(1,2)\n",
    "    grad_W = grad_W_all.mean(axis=0)\n",
    "    W -=  grad_W\n",
    "    b -= grad_b    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test data 的正確率\n",
    "((W @ test_X + b).argmax(axis=1).ravel() == test_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# 準確率的圖\n",
    "plt.plot(accuracy_history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loss 的圖\n",
    "plt.plot(loss_history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    t = np.exp(x)\n",
    "    return t/t.sum(axis=(-2,-1),keepdims=True)\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# 微分\n",
    "def Drelu(x):\n",
    "    return (x>0).astype('float32')\n",
    "def Dsigmoid(x):\n",
    "    q = sigmoid(x)\n",
    "    return q * (1-q) \n",
    "    # or \n",
    "    #return np.exp(x)/(1+np.exp(-x))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 參考範例 feedforward network\n",
    "from time import time\n",
    "accuracy_history = []\n",
    "γ = 0.02\n",
    "A = np.random.normal(size=(50,784))\n",
    "b = np.random.normal(size=(50,1))\n",
    "C = np.random.normal(size=(10,50))\n",
    "d = np.random.normal(size=(10,1))\n",
    "t0 = time()\n",
    "for epochs in range(20):\n",
    "    idx = np.random.choice(n_data, n_data, replace=False)\n",
    "    for i in idx:\n",
    "        x = train_X[i]\n",
    "        y = train_y[i]\n",
    "        U_ = A@x+b\n",
    "        U = relu(U_)\n",
    "        q = softmax(C@U+d)\n",
    "        L = - np.log(q[y])[0]\n",
    "        p = np.eye(10)[y][:, None]\n",
    "        grad_d = q - p\n",
    "        grad_C = grad_d @ U.T\n",
    "        grad_b = (C.T @ grad_d ) * Drelu(U_)\n",
    "        grad_A = grad_b @ x.T\n",
    "        A -= γ * grad_A\n",
    "        b -= γ * grad_b\n",
    "        C -= γ * grad_C\n",
    "        d -= γ * grad_d    \n",
    "    score = ((C@relu(A@test_X+b)+d).argmax(axis=1).ravel()==test_y).mean()\n",
    "    print(epochs, score, \"%.1f\"%(time()-t0), L)\n",
    "print(time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
