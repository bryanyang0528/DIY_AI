{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run magic.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain Rule\n",
    "考慮 $F = f(\\mathbf{a},\\mathbf{g}(\\mathbf{b},\\mathbf{h}(\\mathbf{c}, \\mathbf{i}))$\n",
    "\n",
    "$\\mathbf{a},\\mathbf{b},\\mathbf{c},$  代表著權重 , $\\mathbf{i}$ 是輸入\n",
    "\n",
    "站在 \\mathbf{g}  的角度，為了要更新權重，我們想算\n",
    "### $\\frac{\\partial F}{\\partial b_i}$\n",
    "\n",
    "\n",
    "我們需要什麼？ 由 chain rule 得知\n",
    "### $\\frac{\\partial F}{\\partial b_i} = \n",
    "\\sum_j \\frac{\\partial F}{\\partial g_j}\\frac{\\partial g_j}{\\partial b_i}$\n",
    "或者寫成 Jabobian 的形式\n",
    "### $\\frac{\\partial F}{\\partial \\mathbf{b}} = \n",
    "\\frac{\\partial F}{\\partial \\mathbf{g}} \\frac{\\partial \\mathbf{g}}{\\partial \\mathbf{b}}$\n",
    "\n",
    "所以我們希望前面能傳給我們 $\\frac{\\partial F}{\\partial \\mathbf{g}}$\n",
    "\n",
    "\n",
    "將心比心，因為 $\\mathbf{h}$ 也要算 $\\frac{\\partial F}{\\partial \\mathbf{c}}$， 所以我們還要負責傳 $\\frac{\\partial F}{\\partial \\mathbf{h}}$ 給他。 而因為 \n",
    "### $\\frac{\\partial F}{\\partial \\mathbf{h}}=\n",
    "\\frac{\\partial F}{\\partial \\mathbf{g}} \\frac{\\partial \\mathbf{g}}{\\partial \\mathbf{h}}$\n",
    "\n",
    "所以 $\\mathbf{g}$ 中間真正需要負責計算的東西就是 $\\frac{\\partial \\mathbf{g}}{\\partial \\mathbf{h}}$ 和 $\\frac{\\partial \\mathbf{g}}{\\partial \\mathbf{b}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 誤差函數\n",
    "我們的誤差函數還是 Cross entropy， \n",
    "假設輸入值 $x$ 對應到的真實類別是 $y$, 那我們定義誤差函數\n",
    "\n",
    "## $ loss = -\\log(q_y)=- \\log(Predict(Y=y|x)) $\n",
    "\n",
    "\n",
    "或比較一般的\n",
    "\n",
    "## $ loss = - p \\cdot \\log q  $\n",
    "\n",
    "其中 $ p_i = \\Pr(Y=i|x) $ 代表真實發生的機率\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以一層 hidden layer  的 feedforward neural network 來看\n",
    "## $ L= loss = -p \\cdot \\log \\sigma(C(f(Ax+b))+d) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由於\n",
    "### $-\\log \\sigma (Z) = 1 \\log (\\sum e^{Z_j})-Z$\n",
    "### $\\frac{\\partial -\\log \\sigma (Z)}{\\partial Z} = 1 \\sigma(Z)^T - \\delta$\n",
    "let $U = f(Ax+b) $,   $Z=CU+d$\n",
    "\n",
    "### $ \\frac{\\partial L}{\\partial d} = \\frac{\\partial L}{\\partial Z} \\frac{\\partial CU+d}{\\partial d} \n",
    "= \\frac{\\partial L}{\\partial Z}\n",
    "= p^T (1 \\sigma(Z)^T - \\delta)\n",
    "=  \\sigma(Z)^T - p^T\n",
    "=  \\sigma(CU+d)^T - p^T\n",
    "$\n",
    "\n",
    "### $ \\frac{\\partial L}{\\partial C_{i,j} } \n",
    "= \\frac{\\partial L}{\\partial Z} \\frac{\\partial CU+d}{\\partial C_{i,j}} \n",
    "= (p^T (1 \\sigma(Z)^T - \\delta))_i U_j \n",
    "=  (\\sigma(Z) - p)_i   U_j\n",
    "$\n",
    "所以\n",
    "\n",
    "### $ \\frac{\\partial L}{\\partial C } \n",
    "=  (\\sigma(Z) - p)   U^T\n",
    "$\n",
    "\n",
    "到目前為止，都跟原來 softmax 的結果一樣。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "繼續計算 A, b 的偏微分\n",
    "### $ \\frac{\\partial L}{\\partial U } \n",
    "= \\frac{\\partial L}{\\partial Z} \\frac{\\partial CU+d}{\\partial U} \n",
    "= (p^T (1 \\sigma(Z)^T - \\delta)) C\n",
    "=  (\\sigma(Z) - p)^T C\n",
    "$\n",
    "\n",
    "$ \\frac{\\partial U_k}{\\partial b_i} \n",
    "= \\frac{\\partial f(A_kx+b_k)}{\\partial b_i}\n",
    "= \\delta_{k,i} f'(Ax+b)_i $\n",
    "\n",
    "$  \\frac{\\partial L}{\\partial b_i } \n",
    "=  ((\\sigma(Z) - p)^T C)_i f'(Ax+b)_i$\n",
    "\n",
    "$  \\frac{\\partial L}{\\partial A_{i,j} } \n",
    "=  ((\\sigma(Z) - p)^T C)_i f'(Ax+b)_i x_j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
